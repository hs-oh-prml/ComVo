seed_everything: 4444

data:
  class_path: exp.dataset.AudioDataModule
  init_args:
    train_params:
      filelist_path: filelist.train
      sampling_rate: 24000
      num_samples: 16384
      batch_size: 16
      num_workers: 8

    val_params:
      filelist_path: filelist.val
      sampling_rate: 24000
      num_samples: 48384
      batch_size: 16
      num_workers: 8

model:
  class_path: exp.experiment_cdisc.ComVo
  init_args:
    sample_rate: 24000
    initial_learning_rate: 2e-4
    mel_loss_coeff: 45
    mrd_loss_coeff: 0.1
    num_warmup_steps: 0 
    pretrain_mel_steps: 0  
    
    evaluate_utmos: true
    evaluate_pesq: true
    evaluate_periodicty: true

    feature_extractor:
      class_path: exp.feature_extractors.MelSpectrogramFeatures
      init_args:
        sample_rate: 24000
        n_fft: 1024
        hop_length: 256
        n_mels: 100
        padding: center

    backbone:
      class_path: exp.models.ComVo
      init_args:
        input_channels: 100
        dim: 512
        intermediate_dim: 1536
        num_layers: 8
        n_quantization: 128
    head:
      class_path: exp.heads.ISTFTHead
      init_args:
        dim: 512
        n_fft: 1024
        hop_length: 256
        padding: center

trainer:
  logger:
    class_path: pytorch_lightning.loggers.TensorBoardLogger
    init_args:
      save_dir: "./checkpoints/ComVo"
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    - class_path: pytorch_lightning.callbacks.ModelSummary
      init_args:
        max_depth: 2
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val_loss
        filename: checkpoint_{epoch}_{step}_{val_loss:.4f}
        save_top_k: 3
        save_last: true
    - class_path: exp.helpers.GradNormCallback
  max_steps: 2000000
  limit_val_batches: 100
  accelerator: gpu
  strategy: dp
  devices: [0]
  log_every_n_steps: 100
